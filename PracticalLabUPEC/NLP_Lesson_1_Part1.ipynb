{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq1CyjkjU6IH"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rolWxTAU6IN"
      },
      "source": [
        "# Lesson I - Text representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8XPRcKUU6IO"
      },
      "source": [
        "In this lesson we will see in some details how we can best represent text in our application. Let's start by importing the modules we will be using:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVX0ipikU6IQ"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "from collections import Counter\n",
        "from pprint import pprint\n",
        "import gzip\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6Zgur--U6IU"
      },
      "source": [
        "We choose a well known nursery rhyme, that has the added distinction of having been the first audio ever recorded, to be the short snippet of text that we will use in our examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFnAlK4sU6IV"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"Mary had a little lamb, little lamb,\n",
        "    little lamb. Mary had a little lamb\n",
        "    whose fleece was white as snow.\n",
        "    And everywhere that Mary went\n",
        "    Mary went, Mary went. Everywhere\n",
        "    that Mary went,\n",
        "    The lamb was sure to go\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lUeOa3MU6IX"
      },
      "source": [
        "## Tokenization\n",
        "\n",
        "The first step in any analysis is to tokenize the text. What this means is that we will extract all the individual words in the text. For the sake of simplicity, we will assume that our text is well formed and that our words are delimited either by white space or punctuation characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTIQdnCaU6IZ"
      },
      "outputs": [],
      "source": [
        "def extract_words(text):\n",
        "    temp = text.split() # Split the text on whitespace\n",
        "    text_words = []\n",
        "\n",
        "    for word in temp:\n",
        "        # Remove any punctuation characters present in the beginning of the word\n",
        "        while word[0] in string.punctuation:\n",
        "            word = word[1:]\n",
        "\n",
        "        # Remove any punctuation characters present in the end of the word\n",
        "        while word[-1] in string.punctuation:\n",
        "            word = word[:-1]\n",
        "\n",
        "        # Append this word into our list of words.\n",
        "        text_words.append(word.lower())\n",
        "\n",
        "    return text_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0ufTkAjU6Ic"
      },
      "source": [
        "After this step we now have our text represented as an array of individual, lowercase, words:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_jNG20PU6Ig",
        "outputId": "af3d697e-c302-45f2-e0cf-d14b9d5eaf8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['mary', 'had', 'a', 'little', 'lamb', 'little', 'lamb', 'little', 'lamb', 'mary', 'had', 'a', 'little', 'lamb', 'whose', 'fleece', 'was', 'white', 'as', 'snow', 'and', 'everywhere', 'that', 'mary', 'went', 'mary', 'went', 'mary', 'went', 'everywhere', 'that', 'mary', 'went', 'the', 'lamb', 'was', 'sure', 'to', 'go']\n"
          ]
        }
      ],
      "source": [
        "text_words = extract_words(text)\n",
        "print(text_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNUN9Ik5U6Ih"
      },
      "source": [
        "As we saw, this is a wasteful way to represent text. We can be much more efficient by representing each word by a number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlq7ftRjU6Il"
      },
      "outputs": [],
      "source": [
        "word_dict = {}\n",
        "word_list = []\n",
        "vocabulary_size = 0\n",
        "text_tokens = []\n",
        "\n",
        "for word in text_words:\n",
        "    # If we are seeing this word for the first time, create an id for it and added it to our word dictionary\n",
        "    if word not in word_dict:\n",
        "        word_dict[word] = vocabulary_size\n",
        "        word_list.append(word)\n",
        "        vocabulary_size += 1\n",
        "\n",
        "    # add the token corresponding to the current word to the tokenized text.\n",
        "    text_tokens.append(word_dict[word])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UI2Jj2owU6In"
      },
      "source": [
        "When we were tokenizing our text, we also generated a dictionary **word_dict** that maps words to integers and a **word_list** that maps each integer to the corresponding word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSCiJ-FKU6Io",
        "outputId": "def54f62-c000-45ca-f30d-eeac00c2a586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word list: ['mary', 'had', 'a', 'little', 'lamb', 'whose', 'fleece', 'was', 'white', 'as', 'snow', 'and', 'everywhere', 'that', 'went', 'the', 'sure', 'to', 'go'] \n",
            "\n",
            " Word dictionary:\n",
            "{'a': 2,\n",
            " 'and': 11,\n",
            " 'as': 9,\n",
            " 'everywhere': 12,\n",
            " 'fleece': 6,\n",
            " 'go': 18,\n",
            " 'had': 1,\n",
            " 'lamb': 4,\n",
            " 'little': 3,\n",
            " 'mary': 0,\n",
            " 'snow': 10,\n",
            " 'sure': 16,\n",
            " 'that': 13,\n",
            " 'the': 15,\n",
            " 'to': 17,\n",
            " 'was': 7,\n",
            " 'went': 14,\n",
            " 'white': 8,\n",
            " 'whose': 5}\n"
          ]
        }
      ],
      "source": [
        "print(\"Word list:\", word_list, \"\\n\\n Word dictionary:\")\n",
        "pprint(word_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73Y6msOXU6Ip"
      },
      "source": [
        "These two datastructures already proved their usefulness when we converted our text to a list of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aviQnUgIU6Iq",
        "outputId": "98a1a561-d5e9-429d-fb26-5f08a191d7b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4, 3, 4, 3, 4, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 0, 14, 0, 14, 0, 14, 12, 13, 0, 14, 15, 4, 7, 16, 17, 18]\n"
          ]
        }
      ],
      "source": [
        "print(text_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZanJA_IoU6Ir"
      },
      "source": [
        "Unfortunately, while this representation is convenient for memory reasons it has some severe limitations. Perhaps the most important of which is the fact that computers naturally assume that numbers can be operated on mathematically (by addition, subtraction, etc) in a way that doesn't match our understanding of words.\n",
        "\n",
        "## One-hot encoding\n",
        "\n",
        "One typical way of overcoming this difficulty is to represent each word by a one-hot encoded vector where every element is zero except the one corresponding to a specific word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzkGmIpaU6Is"
      },
      "outputs": [],
      "source": [
        "def one_hot(word, word_dict):\n",
        "    \"\"\"\n",
        "        Generate a one-hot encoded vector corresponding to *word*\n",
        "    \"\"\"\n",
        "\n",
        "    vector = np.zeros(len(word_dict))\n",
        "    vector[word_dict[word]] = 1\n",
        "\n",
        "    return vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ak6NhOc4U6Iu"
      },
      "source": [
        "So, for example, the word \"fleece\" would be represented by:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqd8W9knU6Iu",
        "outputId": "02fc57c1-77b4-4631-a70c-0258b4e06d88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "fleece_hot = one_hot(\"fleece\", word_dict)\n",
        "print(fleece_hot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqFpUNEOU6Iv"
      },
      "source": [
        "This vector has every element set to zero, except element 6, since:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHLiDeImU6Ix",
        "outputId": "ee6851b4-24c2-45b7-9e25-9a346252ebb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(word_dict[\"fleece\"])\n",
        "fleece_hot[6] == 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8NLWBt7U6Iz"
      },
      "source": [
        "## Bag of words\n",
        "\n",
        "We can now use the one-hot encoded vector for each word to produce a vector representation of our original text, by simply adding up all the one-hot encoded vectors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OnWGjdhU6I0",
        "outputId": "63cd1e20-6e01-4a45-e6c0-5d17c204d576"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[6. 2. 2. 4. 5. 1. 1. 2. 1. 1. 1. 1. 2. 2. 4. 1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "text_vector1 = np.zeros(vocabulary_size)\n",
        "\n",
        "for word in text_words:\n",
        "    hot_word = one_hot(word, word_dict)\n",
        "    text_vector1 += hot_word\n",
        "\n",
        "print(text_vector1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EruiN7TmU6I2"
      },
      "source": [
        "In practice, we can also easily skip the encoding step at the word level by using the *word_dict* defined above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixJjnYk0U6I4",
        "outputId": "5a325da4-7eb4-4f47-d0bd-529b3702f69d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6. 2. 2. 4. 5. 1. 1. 2. 1. 1. 1. 1. 2. 2. 4. 1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "text_vector = np.zeros(vocabulary_size)\n",
        "\n",
        "for word in text_words:\n",
        "    text_vector[word_dict[word]] += 1\n",
        "\n",
        "print(text_vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C_lnQxIU6I5"
      },
      "source": [
        "Naturally, this approach is completely equivalent to the previous one and has the added advantage of being more efficient in terms of both speed and memory requirements.\n",
        "\n",
        "This is known as the __bag of words__ representation of the text. It should be noted that these vectors simply contains the number of times each word appears in our document, so we can easily tell that the word *mary* appears exactly 6 times in our little nursery rhyme."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohbZMJkdU6I7",
        "outputId": "ed3f124f-ae5b-421d-860d-5007512cec81"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "text_vector[word_dict[\"mary\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrHezdOOU6I7"
      },
      "source": [
        "A more pythonic (and efficient) way of producing the same result is to use the standard __Counter__ module:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tPjH90RU6I8",
        "outputId": "3ec37a8a-5c0a-432d-a7bc-63605fbe049b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counter({'mary': 6,\n",
            "         'lamb': 5,\n",
            "         'little': 4,\n",
            "         'went': 4,\n",
            "         'had': 2,\n",
            "         'a': 2,\n",
            "         'was': 2,\n",
            "         'everywhere': 2,\n",
            "         'that': 2,\n",
            "         'whose': 1,\n",
            "         'fleece': 1,\n",
            "         'white': 1,\n",
            "         'as': 1,\n",
            "         'snow': 1,\n",
            "         'and': 1,\n",
            "         'the': 1,\n",
            "         'sure': 1,\n",
            "         'to': 1,\n",
            "         'go': 1})\n"
          ]
        }
      ],
      "source": [
        "word_counts = Counter(text_words)\n",
        "pprint(word_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDoGJOStU6I9"
      },
      "source": [
        "From which we can easily generate the __text_vector__ and __word_dict__ data structures:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ONOLAY_U6I_"
      },
      "outputs": [],
      "source": [
        "items = list(word_counts.items())\n",
        "\n",
        "# Extract word dictionary and vector representation\n",
        "word_dict2 = dict([[items[i][0], i] for i in range(len(items))])\n",
        "text_vector2 = [items[i][1] for i in range(len(items))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC3pPM1sU6JA"
      },
      "source": [
        "And let's take a look at them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "TN2dGAF7U6JB",
        "outputId": "eb5434f7-d0d3-4e90-cc57-ae24af85d081"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'text_vector2' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-ae989c187d47>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Text vector:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_vector2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\nWord dictionary:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_dict2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'text_vector2' is not defined"
          ]
        }
      ],
      "source": [
        "print(\"Text vector:\", text_vector2, \"\\n\\nWord dictionary:\")\n",
        "pprint(word_dict2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50CXicuEU6JB"
      },
      "source": [
        "The results using this approach are slightly different than the previous ones, because the words are mapped to different integer ids but the corresponding values are the same:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzX5etxYU6JC"
      },
      "outputs": [],
      "source": [
        "for word in word_dict.keys():\n",
        "    if text_vector[word_dict[word]] != text_vector2[word_dict2[word]]:\n",
        "        print(\"Error!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDSCxVarU6JD"
      },
      "source": [
        "As expected, there are no differences!"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}